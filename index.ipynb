{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification with Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, BatchNormalization, MaxPool2D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(123)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create data generators with rescaling \n",
    "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory('chest_xray/train/', target_size=(64, 64), batch_size=5216)\n",
    "test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory('chest_xray/test/', target_size=(64, 64), batch_size=624)\n",
    "val_generator = ImageDataGenerator(rescale=1./255).flow_from_directory('chest_xray/val/', target_size=(64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve a batch of training images and their corresponding labels\n",
    "train_images, train_labels = next(train_generator)\n",
    "\n",
    "# Retrieve a batch of test images and their corresponding labels\n",
    "test_images, test_labels = next(test_generator)\n",
    "\n",
    "# Retrieve a batch of validation images and their corresponding labels\n",
    "val_images, val_labels = next(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5216, 64, 64, 3), (5216, 2))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the shape of the train_images and train_labels\n",
    "train_images.shape, train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((624, 64, 64, 3), (624, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the shape of the test_images and test_labels\n",
    "test_images.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16, 64, 64, 3), (16, 2))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the shape of the val_images and val_labels\n",
    "val_images.shape, val_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The label's shape indicates that this is a binary classification problem. The labels suggest that the images can only represent two classes: \"normal\" or \"pneumonia,\" which implies that the goal is to determine whether a patient has pneumonia or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattening the train set to all for modeling\n",
    "train_reshaped = train_images.reshape(5216, 64*64*3)\n",
    "\n",
    "# Flattening the test set to all for modeling\n",
    "test_reshape = test_images.reshape(624, 64*64*3)\n",
    "\n",
    "# Flattening the validation set to all for modeling\n",
    "val_reshape = val_images.reshape(16, 64*64*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                786496    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 792802 (3.02 MB)\n",
      "Trainable params: 792802 (3.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# initialized the model\n",
    "dense_model = Sequential()\n",
    "\n",
    "# Input Layer\n",
    "dense_model.add(Dense(64, activation='relu', input_shape=(64*64*3,)))\n",
    "# Hidden Layer\n",
    "dense_model.add(Dense(64, activation=\"relu\"))\n",
    "dense_model.add(Dense(32, activation=\"LeakyReLU\"))\n",
    "# Output Layer\n",
    "dense_model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "dense_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the dense neural network model\n",
    "dense_model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss= \"binary_crossentropy\",\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a EarlyStopping callback to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=4, mode='min')\n",
    "\n",
    "# Defining the path for saving checkpoints\n",
    "checkpoint_filepath = 'dense_model.h5'\n",
    "\n",
    "# Create a ModelCheckpoint callback to save the best model weights\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    checkpoint_filepath,\n",
    "    monitor='val_loss',  \n",
    "    save_best_only=True, \n",
    "    mode='min',  \n",
    "    verbose=1  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
